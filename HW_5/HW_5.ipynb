{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PmFITaKlbO0",
        "colab_type": "text"
      },
      "source": [
        "# **General concepts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKAGPhc8l5n3",
        "colab_type": "text"
      },
      "source": [
        "## What is Artificial Intelligence?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz8Men07yY2d",
        "colab_type": "text"
      },
      "source": [
        "Artificial Intelligence can be traced back to man's first inception of automatic, mechanical tools or machines.\n",
        "\n",
        "Ancient records detail that with the invention of machines, humanity naturally began to relate them to the likeness of living beings for there weren't any non-living things that could act in such unique, defined, and particular ways. As machines have evolved, so too has humanity's interest in Artificial Intelligence.\n",
        "\n",
        "At first, machines were constructed in human and animalia form. We often regarded such creations with intrigue and as our mechanical prowess improved, we were able to make them increasingly more life-like and more advanced.\n",
        "\n",
        "However, it wasn't until the invention of the computer that Artificial Intelligence was really thrust to the forefront of human culture. With the advent of the computer, complexity and machine intelligence was increasingly easier to develop and thus Artificial Intelligence became more advanced than ever before. Serious concerns started to arise that these computers could, potentially, become more intelligent than we human beings given it is able to self-learn in a generalized way.\n",
        "\n",
        "This perfectly matched the 80s culture in the west and from it, social and entertainment value was gained. Movies, games, books, all forms of media and entertainment harped on the idea. From this massive public interest, funding was thrust into professional, academic research of Artificial Intelligence and its possibilities. This brings us to the computational domain of Artificial Intelligence.\n",
        "\n",
        "Artificial Intelligence can refer to many things. It can refer to machines and how they do complex tasks that only lifeforms have been able to do. It can refer to robotic beings that have consciousness and could supplant humanity. Or it can refer to a computational field of algorithms.\n",
        "\n",
        "The computational field of Artificial Intelligence was created near the 1950s. It started with simple, automated algorithms to play chess, the famous Turing Test, and a bot that could play checkers which then developed into advanced Bayesian algorithms, industrial assembly line robots, semantic nets, path finding algorithms (dijkstra's, iterative deepening, DFS, best-first search), perceptrons, constraint propagation (forward checking, k-consistency, DPLL and Resolution), Huffman-Clowes Labeling, and an untold amount of other algorithms.\n",
        "\n",
        "These rule-based and search-focused algorithms are now, oftentimes referred to as Classical Artificial Intelligence. After these algorithms, there were some massive breakthroughs which have reformed the Artificial Intelligence field we know today."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_ez46JZyROS",
        "colab_type": "text"
      },
      "source": [
        "## What is Machine Learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9R1ptNLElxb",
        "colab_type": "text"
      },
      "source": [
        "The most significant advancement in modern Artificial Intelligence is Machine Learning. Machine Learning has brought us subdomains such as Natural Language Processing (NLP) and Deep Learning. Revolutionary and groundbreaking techniques which allow us to compute in a way that has never been seen before.\n",
        "\n",
        "One of the biggest pitfalls to Rule-based Artificial Intelligence is subjectivity. Humans are able to reason and compute subjective things, but with Rule-based Artificial Intelligence, unless every component is explicitly defined and written, it is difficult for it to succeed, so subjective matters are nigh on impossible to compute.\n",
        "\n",
        "Machine Learning on the otherhand, is able to compute subjective things. Using statistics and probability, Machine Learning can take a large amount of abstract data, learn from it, reinforce itself, and become more atuned to said data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obUiw_CqyUf8",
        "colab_type": "text"
      },
      "source": [
        "## What is Deep Learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gDUJbBHH63f",
        "colab_type": "text"
      },
      "source": [
        "A subset of Machine Learning, Deep Learning is also able to learn as we give it more data, but Deep Learning relies on Neural Networks. Neural Networks enable learning through accuracy. If a network's accuracy is low, the network can automatically adjust itself to account for the failure whereas in Machine Learning the programmer may have to manually modify the code to ensure learning. Thus, Deep Learning is a completely automated learning process similar to how living beings learn.\n",
        "\n",
        "It is most well known for its hand in Natural Language Processing and Image Classification, taking major problems with little success and turning them around with extraordinary results. Not to mention the other applications that affect everyday lives such as learning user preferences to curate experiences on the internet, spell checking and prediction, and translation. Deep Learning is, without a doubt, one of the greatest breakthroughs of our time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5g7xMVAleLh",
        "colab_type": "text"
      },
      "source": [
        "# **Basic concepts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bult6eUTL7dI",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpcsEfrvQ4aj",
        "colab_type": "text"
      },
      "source": [
        "Linear Regression is a way of approximating trends in data linearly. Using this approximation on certain types of data, results in the ability to take advantage of patterns and predict trends.\n",
        "\n",
        "It starts with the linear formula $y = mx+b$. If you plot multiple points of data along the $x$ axis, a line of best fit can be approximated. Henceforth, if that data's trend can be represented accurately with the linear formula, it can be predicted given an $x$ value.\n",
        "\n",
        "Thus we obtain the formula $\\hat{y}= b + w_1x_1$. Where there must be a bias $b$, some slope aka weight $w_1$ and some $x$ value $x_1$. This can be generalized to $\\hat{y}= b + \\sum_{i=1}^{n} w_ix_i$ for multiple slopes/weights and input values.\n",
        "\n",
        "Weights are different than slopes such that they indicate they aren't perfect, can change, and are related to Neural Networks. The bias is the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ph8cwsUL-MP",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g1OsvOKY7qX",
        "colab_type": "text"
      },
      "source": [
        "With Linear Regression, we approximated trends *linearly*. Logistic Regression is similar in which it also approximates trends, but it approximates them along the sigmoid function.\n",
        "\n",
        "The sigmoid function is defined as $\\sigma(z)=\\frac{1}{1+e^{-z}}$. Notice it takes $z$ as a parameter. $z$ here is actually $\\hat{y}$. Thus the sigmoid function can be written as $\\sigma(\\hat{y})=\\frac{1}{1+e^{-\\hat{y}}}$.\n",
        "\n",
        "This means Logistic Regression is approximated with the sigmoid function along $\\hat{y}$.\n",
        "\n",
        "Logistic Regression is useful for classification problems where the answer is categorical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5ZTVWFwML75",
        "colab_type": "text"
      },
      "source": [
        "## Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ggOU7lcd8ey",
        "colab_type": "text"
      },
      "source": [
        "A gradient reflects a function's growth. It is used in Gradient Descent in Machine Learning to help the computer find the direction of greatest increase. The minimum or maximum of the gradient gives us the most optimal weights and by approaching the minimum or maximum, we can optimize for them. By finding the minimum or maximum, we have achieved the best possible result for our configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4WOILl0jdEf",
        "colab_type": "text"
      },
      "source": [
        "![img](https://i.imgur.com/YGOGzJb.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTewanC_MNzn",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iubghOyBfu8c",
        "colab_type": "text"
      },
      "source": [
        "In a Neural Network, we wish to find the most optimal weights. Aka the weights that fit the data in the best possible way and make our predictions as accurate as possible. We do this by updating the weights continuously. Each time the network iterates in training, accuracy is noted and the weights are adjusted accordingly. But it needs to be determined *how much* to update the weights. We don't want to overshoot the optimal value, but if we undershoot too much, it could take us an eternity to find the optimal value. So, how do we solve this problem? How do we adjust the weights?\n",
        "\n",
        "The answer: Gradient Descent. Using Gradient Descent, we can take into account how off we are from the optimal weight value. If our weight values are far off, then we adjust the weights a lot. If our weight values are very close, then we adjust the weight values just a bit. Every time we iterate through our data, we adjust our weights down a gradient for our function. This adjustment amount is also called the learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvq7iYX_kbnp",
        "colab_type": "text"
      },
      "source": [
        "![image](https://i.imgur.com/O1zGIto.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBUWo5Tohy6s",
        "colab_type": "text"
      },
      "source": [
        "### Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osItEX6LiLYL",
        "colab_type": "text"
      },
      "source": [
        "**Stochastic Gradient Descent**: We randomly select a single piece of data, perform a gradient descent on that data, and update our weights accordingly.\n",
        "\n",
        "**Batch Gradient Descent**: We use the entire batch of data to perform a gradient descent and then update our weights accordingly.\n",
        "\n",
        "**Mini-Batch Gradient Descent**: We use a portion of our batch of data to perform a gradient descent and then update our weights accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJuTRd1lOiJZ",
        "colab_type": "text"
      },
      "source": [
        "## An Example Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDMP_5lwRKdT",
        "colab_type": "text"
      },
      "source": [
        "We train a couple weights and a bias on some randomized data to showcase stochastic gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqh5dQ3iVy4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random as random\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-at47spiqfF",
        "colab_type": "text"
      },
      "source": [
        "### Generate randomized data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8ZlPgIsj1Ar",
        "colab_type": "text"
      },
      "source": [
        "This isn't important to understanding gradient descent. All that needs to be known is that this function generates some labeled/truthed data which we can perform gradient descent on, but if you care to read further, feel free.\n",
        "\n",
        "We have two features for each segment of data: $x_1$ and $x_2$.    \n",
        "$x_1 = \\{$Some value on the interval $ [0,1)\\} \\,\\,\\,\\,\\,\\, x_2 = w*x_1+b+n*(-1)^c$    \n",
        "Where $n = \\{$Some value randomly sampled from a normal distribution of properties $\\mu$ and $\\sigma\\}$ and, $b$ and $w$ are passed as inputs.    \n",
        "We then compute $m$ of these segments to generate an entire set of randomized data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUWippAcVzeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generates randomized data according to functions\n",
        "# and given input parameters.\n",
        "def get_random_data(w, b, mu, sigma, m):\n",
        "  data = []\n",
        "  labels = np.random.randint(2, size=m)\n",
        "\n",
        "  for i in range(m):\n",
        "    c = labels[i]\n",
        "    n = np.random.normal(mu, sigma)\n",
        "\n",
        "    # The functions used\n",
        "    x_1 = random.random()\n",
        "    x_2 = w * x_1 + b + ((-1)**c) * n\n",
        "\n",
        "    data.append([x_1, x_2])\n",
        "  \n",
        "  data = np.array(data)\n",
        "  return data, labels\n",
        "\n",
        "# The input parameters for the generated data.\n",
        "truth_weight = 40\n",
        "truth_bias = 30\n",
        "truth_mu = 25\n",
        "truth_sigma = 7\n",
        "truth_m = 10000\n",
        "\n",
        "# Generate the randomized data.\n",
        "data, labels =  get_random_data(truth_weight, truth_bias, truth_mu, truth_sigma, truth_m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrK3Zon5c4rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Divide up the data into testing and training sets.\n",
        "training_data = data[:7999]\n",
        "training_labels = labels[:7999]\n",
        "testing_data = data[8000:]\n",
        "testing_labels = labels[8000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mzf_nHYFHrCk"
      },
      "source": [
        "### Stochastic Gradient Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxEFzhuHEHPF",
        "colab_type": "text"
      },
      "source": [
        "##### Sigmoid function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM9ui3J4Fos8",
        "colab_type": "text"
      },
      "source": [
        "The sigmoid function is the loss function used in stochastic gradient logistic regression. It is defined as $\\sigma(z)=\\frac{1}{1+e^{-z}}$. It is used to help calculate the gradient magnitude."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL3T_ZZtrnAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Performs the sigmoid function.\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbvcL4rsEaes",
        "colab_type": "text"
      },
      "source": [
        "##### Network training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKXXmveHFjDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network input parameters.\n",
        "epochs = 250\n",
        "lr = 0.01\n",
        "\n",
        "# Initialization of network weights and bias.\n",
        "w_1 = np.random.randn(1)\n",
        "w_2 = np.random.randn(1)\n",
        "b_1 = np.zeros(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyoeDWoEIOLK",
        "colab_type": "text"
      },
      "source": [
        "In order to train the network, some steps need to be taken. We iterate through each epoch, continually updating the weights and the bias through stochastic gradient descent.    \n",
        "    \n",
        "Gradient descent in the code here, includes three important formulas.    \n",
        "First, the $y_p = w_1 * x_1 + w_2 * x_2 + b_1$ formula is realized to find a prediction given certain input values $x_1$ and $x_2$. Once calculated, $y_p$ is used as input to the sigmoid function $a = \\sigma(z)$.    \n",
        "Next, $a$ is used as input to gradient descent formulas such as $g_{w1} = (a - y) * x_1$.    \n",
        "Lastly, gradients are used as input to 'descent' formulas such as $w_1 = w_1 - LR * g_{w1}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96zhsNynrfTv",
        "colab_type": "code",
        "outputId": "f4e28b37-3e69-4f96-baf9-60084cb0f06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training a stochastic gradient logistic regression model.\n",
        "for epoch in np.arange(epochs):\n",
        "    print(\"Epoch \" + str(epoch+1) + \"/\" + str(epochs))\n",
        "\n",
        "    # Iterate through all features.\n",
        "    for i in np.arange(len(training_data)):\n",
        "        # Calculate predictions.\n",
        "        y_pred = w_1 * training_data[i][0] + w_2 * training_data[i][1] + b_1\n",
        "        a = sigmoid(y_pred)\n",
        "        \n",
        "        # Perform gradient descent.\n",
        "        grad_w_1 = (a - training_labels[i]) * training_data[i][0]\n",
        "        grad_w_2 = (a - training_labels[i]) * training_data[i][1]\n",
        "        grad_b_1 = (a - training_labels[i])\n",
        "        \n",
        "        # Apply to weights and bias.\n",
        "        w_1 -= lr * grad_w_1\n",
        "        w_2 -= lr * grad_w_2\n",
        "        b_1 -= lr * grad_b_1"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "Epoch 2/250\n",
            "Epoch 3/250\n",
            "Epoch 4/250\n",
            "Epoch 5/250\n",
            "Epoch 6/250\n",
            "Epoch 7/250\n",
            "Epoch 8/250\n",
            "Epoch 9/250\n",
            "Epoch 10/250\n",
            "Epoch 11/250\n",
            "Epoch 12/250\n",
            "Epoch 13/250\n",
            "Epoch 14/250\n",
            "Epoch 15/250\n",
            "Epoch 16/250\n",
            "Epoch 17/250\n",
            "Epoch 18/250\n",
            "Epoch 19/250\n",
            "Epoch 20/250\n",
            "Epoch 21/250\n",
            "Epoch 22/250\n",
            "Epoch 23/250\n",
            "Epoch 24/250\n",
            "Epoch 25/250\n",
            "Epoch 26/250\n",
            "Epoch 27/250\n",
            "Epoch 28/250\n",
            "Epoch 29/250\n",
            "Epoch 30/250\n",
            "Epoch 31/250\n",
            "Epoch 32/250\n",
            "Epoch 33/250\n",
            "Epoch 34/250\n",
            "Epoch 35/250\n",
            "Epoch 36/250\n",
            "Epoch 37/250\n",
            "Epoch 38/250\n",
            "Epoch 39/250\n",
            "Epoch 40/250\n",
            "Epoch 41/250\n",
            "Epoch 42/250\n",
            "Epoch 43/250\n",
            "Epoch 44/250\n",
            "Epoch 45/250\n",
            "Epoch 46/250\n",
            "Epoch 47/250\n",
            "Epoch 48/250\n",
            "Epoch 49/250\n",
            "Epoch 50/250\n",
            "Epoch 51/250\n",
            "Epoch 52/250\n",
            "Epoch 53/250\n",
            "Epoch 54/250\n",
            "Epoch 55/250\n",
            "Epoch 56/250\n",
            "Epoch 57/250\n",
            "Epoch 58/250\n",
            "Epoch 59/250\n",
            "Epoch 60/250\n",
            "Epoch 61/250\n",
            "Epoch 62/250\n",
            "Epoch 63/250\n",
            "Epoch 64/250\n",
            "Epoch 65/250\n",
            "Epoch 66/250\n",
            "Epoch 67/250\n",
            "Epoch 68/250\n",
            "Epoch 69/250\n",
            "Epoch 70/250\n",
            "Epoch 71/250\n",
            "Epoch 72/250\n",
            "Epoch 73/250\n",
            "Epoch 74/250\n",
            "Epoch 75/250\n",
            "Epoch 76/250\n",
            "Epoch 77/250\n",
            "Epoch 78/250\n",
            "Epoch 79/250\n",
            "Epoch 80/250\n",
            "Epoch 81/250\n",
            "Epoch 82/250\n",
            "Epoch 83/250\n",
            "Epoch 84/250\n",
            "Epoch 85/250\n",
            "Epoch 86/250\n",
            "Epoch 87/250\n",
            "Epoch 88/250\n",
            "Epoch 89/250\n",
            "Epoch 90/250\n",
            "Epoch 91/250\n",
            "Epoch 92/250\n",
            "Epoch 93/250\n",
            "Epoch 94/250\n",
            "Epoch 95/250\n",
            "Epoch 96/250\n",
            "Epoch 97/250\n",
            "Epoch 98/250\n",
            "Epoch 99/250\n",
            "Epoch 100/250\n",
            "Epoch 101/250\n",
            "Epoch 102/250\n",
            "Epoch 103/250\n",
            "Epoch 104/250\n",
            "Epoch 105/250\n",
            "Epoch 106/250\n",
            "Epoch 107/250\n",
            "Epoch 108/250\n",
            "Epoch 109/250\n",
            "Epoch 110/250\n",
            "Epoch 111/250\n",
            "Epoch 112/250\n",
            "Epoch 113/250\n",
            "Epoch 114/250\n",
            "Epoch 115/250\n",
            "Epoch 116/250\n",
            "Epoch 117/250\n",
            "Epoch 118/250\n",
            "Epoch 119/250\n",
            "Epoch 120/250\n",
            "Epoch 121/250\n",
            "Epoch 122/250\n",
            "Epoch 123/250\n",
            "Epoch 124/250\n",
            "Epoch 125/250\n",
            "Epoch 126/250\n",
            "Epoch 127/250\n",
            "Epoch 128/250\n",
            "Epoch 129/250\n",
            "Epoch 130/250\n",
            "Epoch 131/250\n",
            "Epoch 132/250\n",
            "Epoch 133/250\n",
            "Epoch 134/250\n",
            "Epoch 135/250\n",
            "Epoch 136/250\n",
            "Epoch 137/250\n",
            "Epoch 138/250\n",
            "Epoch 139/250\n",
            "Epoch 140/250\n",
            "Epoch 141/250\n",
            "Epoch 142/250\n",
            "Epoch 143/250\n",
            "Epoch 144/250\n",
            "Epoch 145/250\n",
            "Epoch 146/250\n",
            "Epoch 147/250\n",
            "Epoch 148/250\n",
            "Epoch 149/250\n",
            "Epoch 150/250\n",
            "Epoch 151/250\n",
            "Epoch 152/250\n",
            "Epoch 153/250\n",
            "Epoch 154/250\n",
            "Epoch 155/250\n",
            "Epoch 156/250\n",
            "Epoch 157/250\n",
            "Epoch 158/250\n",
            "Epoch 159/250\n",
            "Epoch 160/250\n",
            "Epoch 161/250\n",
            "Epoch 162/250\n",
            "Epoch 163/250\n",
            "Epoch 164/250\n",
            "Epoch 165/250\n",
            "Epoch 166/250\n",
            "Epoch 167/250\n",
            "Epoch 168/250\n",
            "Epoch 169/250\n",
            "Epoch 170/250\n",
            "Epoch 171/250\n",
            "Epoch 172/250\n",
            "Epoch 173/250\n",
            "Epoch 174/250\n",
            "Epoch 175/250\n",
            "Epoch 176/250\n",
            "Epoch 177/250\n",
            "Epoch 178/250\n",
            "Epoch 179/250\n",
            "Epoch 180/250\n",
            "Epoch 181/250\n",
            "Epoch 182/250\n",
            "Epoch 183/250\n",
            "Epoch 184/250\n",
            "Epoch 185/250\n",
            "Epoch 186/250\n",
            "Epoch 187/250\n",
            "Epoch 188/250\n",
            "Epoch 189/250\n",
            "Epoch 190/250\n",
            "Epoch 191/250\n",
            "Epoch 192/250\n",
            "Epoch 193/250\n",
            "Epoch 194/250\n",
            "Epoch 195/250\n",
            "Epoch 196/250\n",
            "Epoch 197/250\n",
            "Epoch 198/250\n",
            "Epoch 199/250\n",
            "Epoch 200/250\n",
            "Epoch 201/250\n",
            "Epoch 202/250\n",
            "Epoch 203/250\n",
            "Epoch 204/250\n",
            "Epoch 205/250\n",
            "Epoch 206/250\n",
            "Epoch 207/250\n",
            "Epoch 208/250\n",
            "Epoch 209/250\n",
            "Epoch 210/250\n",
            "Epoch 211/250\n",
            "Epoch 212/250\n",
            "Epoch 213/250\n",
            "Epoch 214/250\n",
            "Epoch 215/250\n",
            "Epoch 216/250\n",
            "Epoch 217/250\n",
            "Epoch 218/250\n",
            "Epoch 219/250\n",
            "Epoch 220/250\n",
            "Epoch 221/250\n",
            "Epoch 222/250\n",
            "Epoch 223/250\n",
            "Epoch 224/250\n",
            "Epoch 225/250\n",
            "Epoch 226/250\n",
            "Epoch 227/250\n",
            "Epoch 228/250\n",
            "Epoch 229/250\n",
            "Epoch 230/250\n",
            "Epoch 231/250\n",
            "Epoch 232/250\n",
            "Epoch 233/250\n",
            "Epoch 234/250\n",
            "Epoch 235/250\n",
            "Epoch 236/250\n",
            "Epoch 237/250\n",
            "Epoch 238/250\n",
            "Epoch 239/250\n",
            "Epoch 240/250\n",
            "Epoch 241/250\n",
            "Epoch 242/250\n",
            "Epoch 243/250\n",
            "Epoch 244/250\n",
            "Epoch 245/250\n",
            "Epoch 246/250\n",
            "Epoch 247/250\n",
            "Epoch 248/250\n",
            "Epoch 249/250\n",
            "Epoch 250/250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd9obYpDlimC",
        "colab_type": "text"
      },
      "source": [
        "# **Building a model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsAnjJX2TW5Q",
        "colab_type": "text"
      },
      "source": [
        "## How do you build a model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt-xcq5mmyf_",
        "colab_type": "text"
      },
      "source": [
        "In Deep Learning, models can be made to perform specific tasks. As mentioned before, we can use convnets for image classification, text prediction, NLP, among other things, but in order to get a model that performs a specific task, we have to do two core things: design the network and train it.\n",
        "\n",
        "Let's say we want a network that can tell if a picture is of a cat or a dog. Since we only have two classes, we want a model that can perform binary classification. A model has two main parts: the conv base and the classifier. \n",
        "\n",
        "The conv base takes the given input (an image of a dog or cat in this scenario) and transforms/filters it in various ways. Each transformation is abstracted into something called a layer. These layers are chosen and placed to extract the features of the input that are important for our use case and update values called weights which fit our model to a given set of data through training. For example, we may want to reduce the entropy of our image for better and faster processing so we use some number of convolutional layers to achieve that end. Although, even Machine Learning experts largely use intuition when designing their own models because Deep Learning is very much like a black box. It's hard to know if a design will classify to the accuracy you need without experimenting with different layer types and combinations.\n",
        "\n",
        "The classifier takes the processed input from the conv base and reduces it to our desired output. In this case, a single number that indicates if the input image contains a cat or a dog. The classifier is also abstracted in the form of layers but uses largely different layers than the conv base. Some notable ones include Flatten, Dense, Dropout, Batch Normalization, Softmax, Sigmoid, and ReLU.\n",
        "\n",
        "Designing a network is a lot of work, but thankfully, network designs can be generalized and used for many different, but similar tasks. These are called pre-trained networks. For instance, there are many different models for image classification and they all work quite well at classifying just about any object in any image; therefore building a network to classify pictures of dogs and cats is quite trivial. We simply choose from one of the well known image classification networks such as Xception, freeze some layers, train some others on images of dogs and cats and it's basically done, though we will get into that a bit later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "het5s6OPTe9q",
        "colab_type": "text"
      },
      "source": [
        "## Building a model in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GSs_fzUTn9o",
        "colab_type": "text"
      },
      "source": [
        "There are different frameworks one can use to build and train a neural network, but we will use the most popular one named Tensorflow-Keras or Keras for short."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ48W5T9rHWu",
        "colab_type": "text"
      },
      "source": [
        "#### Load the convolutional base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2O8OMpZT6-Y",
        "colab_type": "text"
      },
      "source": [
        "For our example, we wish to classify images as having either a cat or a dog, thus we use an image classification, pretrained network called Xception. Keras makes this very easy, we just use the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0FgtANCXm_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.xception import Xception\n",
        "\n",
        "conv_base = Xception(\n",
        "    weights='imagenet', \n",
        "    include_top=False, \n",
        "    input_shape=(150, 150, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03gAYe7wVGU3",
        "colab_type": "text"
      },
      "source": [
        "The pretrained network has already been trained on the ImageNet dataset, meaning it already has a lot of information on images we can use. There is more information on this in the \"Finetuning a pretrained model\" section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FLU1cpcVMl3",
        "colab_type": "text"
      },
      "source": [
        "Here are the layers in Xception. Notice how our output is much larger than the single value it needs to be. We learn how to remedy this in the \"Finetuning a pretrained model\" section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh6gZSeAjF7c",
        "colab_type": "code",
        "outputId": "7ac679cf-44f1-474d-a408-ea71a9e7032b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 36, 36, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 18, 18, 256)  32768       add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 18, 18, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 9, 9, 728)    186368      add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 9, 9, 728)    2912        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 5, 5, 1024)   745472      add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 5, 5, 1024)   4096        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eJYjA3dlwy8",
        "colab_type": "text"
      },
      "source": [
        "# **Finetuning a pretrained model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-QXCUQbIkI1",
        "colab_type": "text"
      },
      "source": [
        "Training works a bit differently with pretrained models. Pretrained models are frequently trained on large, generalized datasets and released for public use. For example, most image-based pretrained models like Xception are trained on ImageNet--the largest and most representative general image dataset we have to date. This is great for users of pretrained networks because by default, pretrained networks already have a generalized understanding of image classification.\n",
        "\n",
        "In trained models, the deeper into the network you go, the more precise it gets. Conversely, at the top of the network, the more general it is. The first layers of a network hold many abstract concepts of images which are useful and shouldn't be changed such as edges and shapes, therefore when training pretrained networks, we freeze the weights of the first layers. This improves regularization and classification accuracy. Of course if no weights change, training does nothing and we don't need to classify many objects as in the case of ImageNet, we only need to classify cats and dogs, so it is ok and good for the last layers of a network to be trained.\n",
        "\n",
        "Pretrained models are normally set to output values that are different than what we need. As we mentioned before, we only need a binary classifier for classifying cats and dogs. That is, an output of a single value. For example, Xception was trained on ImageNet which has two hundred different classes, but we only need to output two. Thus, we switch out the classifer of a pretrained network with another classifier built for our use case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsP97h8Waf9v",
        "colab_type": "text"
      },
      "source": [
        "## Finetune our example network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6OBHOO9q1ou",
        "colab_type": "text"
      },
      "source": [
        "#### Freeze parts of the convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwkVMx8N8qMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name[:7] == 'block12' or layer.name == 'add_131':\n",
        "    set_trainable = True\n",
        "  \n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfx6PqhPrb7Q",
        "colab_type": "text"
      },
      "source": [
        "#### Concatenate the convolutional base and our classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd_3yD1Gat8N",
        "colab_type": "text"
      },
      "source": [
        "Notice how we are able to reduce our output to a single value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUpmocDAO3xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c731e3cf-2446-42f1-e623-ab55def04fb6",
        "id": "LQ5FnshSc98e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Model)             (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 34,001,961\n",
            "Trainable params: 21,542,841\n",
            "Non-trainable params: 12,459,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDGYU1TSlpXz",
        "colab_type": "text"
      },
      "source": [
        "# **Compiling a model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AOVgcmEyyeL",
        "colab_type": "text"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXYrtsPKzATi",
        "colab_type": "text"
      },
      "source": [
        "In Gradient Descent we explained how we try to find the optimal weights given a set of data by continually updating our weights bit by bit, but how do we determine how much to update our weights for each iteration? We do this with Optimizers. Optimizers perform varying calculations to try to _optimize_ gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sOiN_C0y7Vu",
        "colab_type": "text"
      },
      "source": [
        "## Learning Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTi_1x1n6UgW",
        "colab_type": "text"
      },
      "source": [
        "In order to understand optimizers, one needs to understand what the Learning Rate is. When performing gradient descent, there exists a gradient magnitude that is used to help determine where the next point in the descent will be, but in order to choose that point, the learning rate is multiplied with the gradient magnitude. Thus, the learning rate determines how much we descend in gradient descent.\n",
        "\n",
        "It's important to be careful and choose a good learning rate because if we choose one that's too large then the network will constantly bounce around the bottom of the gradient, but if we choose one that's too small, the network may never reach the bottom of the gradient and as mentioned before, the bottom of the gradient, gives us the most optimal weight."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLw8JMe18f-P",
        "colab_type": "text"
      },
      "source": [
        "## Modern Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNM56QEf6ToS",
        "colab_type": "text"
      },
      "source": [
        "There are two important, modern optimizers: RMSprop and Adam. There are more but we will only talk about these two.\n",
        "\n",
        "In RMSprop, different weights can have different learning rates, but they are limited by a window and therefore are not only bound by the gradient momentum.\n",
        "\n",
        "In Adam, past gradients are used to optimize for the current one and it implements the idea of momentum.\n",
        "\n",
        "Both are very good, but different optimizers and they should be trialed in image classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ73jzMLXAj_",
        "colab_type": "text"
      },
      "source": [
        "## Configuring an Optimizer in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRidrNESYh3k",
        "colab_type": "text"
      },
      "source": [
        "Keras makes setting an optimizer really easy for us. We simply set our model to RMSprop for this example and our learning rate to $0.00002$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcZdkSBFW6aK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "# compile model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer=optimizers.RMSprop(lr=2e-5), \n",
        "    metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9rJJHNyluEK",
        "colab_type": "text"
      },
      "source": [
        "# **Training a model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhbz9A7ymQao",
        "colab_type": "text"
      },
      "source": [
        "In order to get a model to perform a specific task, we have to train it. When you train a model, you pass the model example data it can use to learn from and output the result you want. For example, we wish for our model to classify a given input image as having a dog or a cat, thus we train a model we've built with as many images as we can of cats and dogs, but we also have to tell the model what image has what classification so it knows how to update the weights. This data is called _truthed_ data. The data we feed it will have labels which indicate which images have dogs and which images have cats.\n",
        "\n",
        "After training a model and building it correctly, we should be able to pass in new images to test how well it is able to do the desired task. This part is often called _validation_ and helpfully most neural network frameworks do this incrementally and automatically as the model is trained. Like our training data, in order to vaidate, we must have input images and their truth, thus before training, it is recommended to take all truthed data and divide it up with 80% going toward training the network and 20% toward validating the network. This way we aren't testing the network based on data it has trained on which would give us _extremely_ warped results.\n",
        "\n",
        "However, there is a problem here. A model is only good as the data it is fed. If we train and evaluate the model on images that are not representative of its final, production use case or conform to that specific data too much, then our model isn't as good as it can be. This is called _overfitting_.\n",
        "\n",
        "If we wish to reduce overfitting (aka regularize), there are a few things we can do. An obvious one is get truthed data as respresentative of the final use case as possible. This means a random sampling of potential inputs and labeling every one of those. If this is not possible, there is something called data augmentation. In data augmentation, we use existing data to create new data to train with. For example, we could reflect all cat and dog images on the y-axis. That would give us more data to train with and hopefully help us get closer to the production use case. Another way to regularize is to change the design of the model. There are types of layers that regularize better than others so those could be used instead. It has also been shown that reducing the complexity of a network, improves regularization.\n",
        "\n",
        "Conversely, it's also important to not underfit. You don't want a model to generalize so much that it ruins its accuracy. This occurs with regularization so it's important to note there's a balance. Validation accuracy will decrease, but regularization will increase. A lot of this is subjective. Mess around with the parameters, try different things, gain intuition, and choose the configuration that seems to work best."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKPGI-MjKGpP",
        "colab_type": "text"
      },
      "source": [
        "## Training a pretrained network with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVxEyzq2Y4-q",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare truthed data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEhF1ntbY_L4",
        "colab_type": "text"
      },
      "source": [
        "We download a truthed dataset of cat and dog images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWjprHEXJ5Qi",
        "colab_type": "code",
        "outputId": "deca9a50-c253-4335-e670-09ff558128c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-25 03:47:12--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.123.128, 2607:f8b0:400c:c15::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.123.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: /tmp/cats_and_dogs_filtered.zip\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   100MB/s    in 0.7s    \n",
            "\n",
            "2020-04-25 03:47:13 (100 MB/s) - /tmp/cats_and_dogs_filtered.zip saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvoHtdA-K6Rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgEKyrqWZHpa",
        "colab_type": "text"
      },
      "source": [
        "We read the image data into Python and divide up the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL8ikM89LlsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJZknXZMZYH0",
        "colab_type": "text"
      },
      "source": [
        "Perform some preprocessing and normalization for Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJvnUK3rXqac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ee1f7e8b-f75b-4532-a607-eb3ae39ace07"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEiJOgBUZfMp",
        "colab_type": "text"
      },
      "source": [
        "#### Train the pretrained network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aNR3dk9Zngh",
        "colab_type": "text"
      },
      "source": [
        "We train for 30 epochs in this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfAQlC2Oi41L",
        "colab_type": "code",
        "outputId": "8f020671-f2aa-4a5b-8ea1-f44e6ca11fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "# train\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            " 37/100 [==========>...................] - ETA: 3:38 - loss: 0.5159 - acc: 0.7419"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ea83153c5aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPih0jvFZuEo",
        "colab_type": "text"
      },
      "source": [
        "#### Display results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcbKgdbtbDxz",
        "colab_type": "text"
      },
      "source": [
        "Let's check out how well our model classifies things."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybWwdzz9bwuQ",
        "colab_type": "code",
        "outputId": "2f72b7fd-e96e-48a2-fb74-db9aad4fa91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# training and validation accuracy\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# training and validation loss\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c08ef5782938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he3Nw6TOJwjx",
        "colab_type": "text"
      },
      "source": [
        "#### Print out validation loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVQtrk7uJdhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss, val_acc = model.evaluate_generator(validation_generator, steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpdddLi1SUMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Validation loss:\", val_loss)\n",
        "print(\"Validation accuracy:\", val_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt7XCsmLDlgj",
        "colab_type": "text"
      },
      "source": [
        "# **Citations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXh0FR_rDnRm",
        "colab_type": "text"
      },
      "source": [
        "- https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence\n",
        "- https://courses.cs.washington.edu/courses/csep573/03wi/lectures/slides/class1.pdf\n",
        "- https://github.com/schneider128k/machine_learning_course/blob/master/slides/2_slides.pdf\n",
        "- https://github.com/nabakin/machine-learning-course/blob/master/HW_3/HW_3.ipynb\n",
        "- https://github.com/nabakin/machine-learning-course/blob/master/HW_4/HW_4_2.ipynb\n",
        "- https://algorithmia.com/blog/introduction-to-optimizers\n",
        "- https://github.com/schneider128k/machine_learning_course/blob/master/slides/2_slides.pdf\n"
      ]
    }
  ]
}